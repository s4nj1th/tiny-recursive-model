{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b48e95",
   "metadata": {},
   "source": [
    "# **TRM**: Tiny Reasoning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb34c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d155b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TRMConfig:\n",
    "    input_dim: int = 81 * 10\n",
    "    hidden_dim: int = 512\n",
    "    output_dim: int = 81 * 9\n",
    "    L_layers: int = 3\n",
    "    H_cycles: int = 4\n",
    "    L_cycles: int = 8\n",
    "    dropout: float = 0.1\n",
    "    \n",
    "    batch_size: int = 64\n",
    "    epochs: int = 50\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 0.01\n",
    "    train_split: float = 0.95\n",
    "    \n",
    "    data_path: str = \"data/sudoku.csv\"\n",
    "    max_samples: Optional[int] = 100000\n",
    "    \n",
    "    save_dir: str = \"checkpoints/\"\n",
    "    model_name: str = \"trm_sudoku_best.pt\"\n",
    "    \n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "config = TRMConfig()\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Device: {config.device}\")\n",
    "print(f\"  Batch Size: {config.batch_size}\")\n",
    "print(f\"  Epochs: {config.epochs}\")\n",
    "print(f\"  Learning Rate: {config.lr}\")\n",
    "print(f\"  H_cycles: {config.H_cycles}, L_cycles: {config.L_cycles}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7630f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * 4, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class TinyRecursiveModel(nn.Module):\n",
    "    def __init__(self, config: TRMConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.input_proj = nn.Linear(config.input_dim, config.hidden_dim)\n",
    "        \n",
    "        self.latent_layers = nn.ModuleList([\n",
    "            ResidualBlock(config.hidden_dim, config.dropout)\n",
    "            for _ in range(config.L_layers)\n",
    "        ])\n",
    "        \n",
    "        self.output_layers = nn.ModuleList([\n",
    "            ResidualBlock(config.hidden_dim, config.dropout)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        \n",
    "        self.output_proj = nn.Linear(config.hidden_dim, config.output_dim)\n",
    "        \n",
    "        self.latent_gate = nn.Parameter(torch.ones(1))\n",
    "        self.output_gate = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    def latent_recursion(self, x, y, z):\n",
    "        combined = x + y + z\n",
    "        for layer in self.latent_layers:\n",
    "            combined = combined + self.latent_gate * layer(combined)\n",
    "        return combined\n",
    "    \n",
    "    def output_refinement(self, y, z):\n",
    "        combined = y + z\n",
    "        for layer in self.output_layers:\n",
    "            combined = combined + self.output_gate * layer(combined)\n",
    "        return combined\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_embedded = self.input_proj(x)\n",
    "        x_embedded = x_embedded.unsqueeze(1)\n",
    "        \n",
    "        y = torch.zeros_like(x_embedded)\n",
    "        z = torch.zeros_like(x_embedded)\n",
    "        \n",
    "        for h in range(self.config.H_cycles):\n",
    "            for l in range(self.config.L_cycles):\n",
    "                z = self.latent_recursion(x_embedded, y, z)\n",
    "            y = self.output_refinement(y, z)\n",
    "        \n",
    "        output = self.output_proj(y.squeeze(1))\n",
    "        return output\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cfb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, max_samples: Optional[int] = None):\n",
    "        print(f\"Loading Sudoku data from {csv_path}...\")\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        if max_samples:\n",
    "            df = df.head(max_samples)\n",
    "        \n",
    "        print(f\"Loaded {len(df)} puzzles\")\n",
    "        \n",
    "        self.quizzes = []\n",
    "        self.solutions = []\n",
    "        \n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Parsing data\"):\n",
    "            quiz = np.array([int(c) for c in row['quizzes']], dtype=np.int32)\n",
    "            solution = np.array([int(c) for c in row['solutions']], dtype=np.int32)\n",
    "            \n",
    "            self.quizzes.append(quiz)\n",
    "            self.solutions.append(solution)\n",
    "        \n",
    "        self.quizzes = np.array(self.quizzes)\n",
    "        self.solutions = np.array(self.solutions)\n",
    "        \n",
    "        print(f\"Quizzes shape: {self.quizzes.shape}\")\n",
    "        print(f\"Solutions shape: {self.solutions.shape}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.quizzes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        quiz = self.quizzes[idx]\n",
    "        solution = self.solutions[idx]\n",
    "        \n",
    "        quiz_onehot = np.zeros((81, 10), dtype=np.float32)\n",
    "        for i, val in enumerate(quiz):\n",
    "            quiz_onehot[i, val] = 1.0\n",
    "        quiz_onehot = quiz_onehot.flatten()\n",
    "        \n",
    "        target = solution - 1\n",
    "        \n",
    "        return torch.FloatTensor(quiz_onehot), torch.LongTensor(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRMTrainer:\n",
    "    def __init__(self, model: TinyRecursiveModel, config: TRMConfig):\n",
    "        self.model = model.to(config.device)\n",
    "        self.config = config\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.lr,\n",
    "            weight_decay=config.weight_decay\n",
    "        )\n",
    "        \n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=config.epochs\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        os.makedirs(config.save_dir, exist_ok=True)\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_accuracies = []\n",
    "    \n",
    "    def calculate_accuracy(self, outputs, targets):\n",
    "        outputs = outputs.view(-1, 81, 9)\n",
    "        predictions = torch.argmax(outputs, dim=-1)\n",
    "        targets = targets.view(-1, 81)\n",
    "        correct = (predictions == targets).float()\n",
    "        return correct.mean().item()\n",
    "    \n",
    "    def train_epoch(self, dataloader):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc=\"Training\")\n",
    "        for inputs, targets in pbar:\n",
    "            inputs = inputs.to(self.config.device)\n",
    "            targets = targets.to(self.config.device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            outputs = outputs.view(-1, 9)\n",
    "            targets_flat = targets.view(-1)\n",
    "            \n",
    "            loss = self.criterion(outputs, targets_flat)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                acc = self.calculate_accuracy(outputs, targets)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{acc*100:.2f}%\"\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        return avg_loss, avg_acc\n",
    "    \n",
    "    def validate(self, dataloader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(dataloader, desc=\"Validating\"):\n",
    "                inputs = inputs.to(self.config.device)\n",
    "                targets = targets.to(self.config.device)\n",
    "                \n",
    "                outputs = self.model(inputs)\n",
    "                outputs_flat = outputs.view(-1, 9)\n",
    "                targets_flat = targets.view(-1)\n",
    "                \n",
    "                loss = self.criterion(outputs_flat, targets_flat)\n",
    "                acc = self.calculate_accuracy(outputs, targets)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_acc += acc\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        return avg_loss, avg_acc\n",
    "    \n",
    "    def train(self, train_loader, val_loader):\n",
    "        print(f\"Training TRM Sudoku Solver\")\n",
    "        print(f\"Model Parameters: {self.model.get_num_params():,}\")\n",
    "        print(f\"Device: {self.config.device}\")\n",
    "        print(f\"Training Samples: {len(train_loader.dataset)}\")\n",
    "        print(f\"Validation Samples: {len(val_loader.dataset)}\")\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        for epoch in range(self.config.epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{self.config.epochs}\")\n",
    "            \n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "            \n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accuracies.append(val_acc)\n",
    "            print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                self.save_checkpoint(self.config.model_name)\n",
    "                print(f\"New best model saved! (Acc: {best_val_acc*100:.2f}%)\")\n",
    "            \n",
    "            self.scheduler.step()\n",
    "        \n",
    "        print(f\"Training Complete!\")\n",
    "        print(f\"Best Validation Accuracy: {best_val_acc*100:.2f}%\")\n",
    "    \n",
    "    def save_checkpoint(self, filename):\n",
    "        path = os.path.join(self.config.save_dir, filename)\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'config': self.config,\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_accuracies': self.val_accuracies\n",
    "        }, path)\n",
    "        print(f\"Checkpoint saved: {path}\")\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        ax1.plot(self.train_losses, label='Train Loss', linewidth=2)\n",
    "        ax1.plot(self.val_losses, label='Val Loss', linewidth=2)\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training and Validation Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        ax2.plot([acc * 100 for acc in self.val_accuracies], \n",
    "                 label='Val Accuracy', linewidth=2, color='green')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.set_title('Validation Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.config.save_dir, 'training_history.png'), dpi=150)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89bb344",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SudokuDataset(config.data_path, max_samples=config.max_samples)\n",
    "\n",
    "train_size = int(config.train_split * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if config.device == \"cuda\" else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if config.device == \"cuda\" else False\n",
    ")\n",
    "\n",
    "print(f\"\\nDataloaders ready!\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3f5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyRecursiveModel(config)\n",
    "\n",
    "trainer = TRMTrainer(model, config)\n",
    "\n",
    "trainer.train(train_loader, val_loader)\n",
    "\n",
    "trainer.plot_training_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef549c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path: str, config: TRMConfig):\n",
    "    model = TinyRecursiveModel(config)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=config.device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(config.device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {checkpoint_path}\")\n",
    "    return model\n",
    "\n",
    "def predict_sudoku(model, quiz, config: TRMConfig):\n",
    "    model.eval()\n",
    "    \n",
    "    quiz_onehot = np.zeros((81, 10), dtype=np.float32)\n",
    "    for i, val in enumerate(quiz):\n",
    "        quiz_onehot[i, val] = 1.0\n",
    "    quiz_onehot = quiz_onehot.flatten()\n",
    "    \n",
    "    input_tensor = torch.FloatTensor(quiz_onehot).unsqueeze(0).to(config.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        output = output.view(81, 9)\n",
    "        prediction = torch.argmax(output, dim=-1).cpu().numpy() + 1\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "def visualize_sudoku(quiz, solution, prediction=None):\n",
    "    fig, axes = plt.subplots(1, 3 if prediction is not None else 2, figsize=(15, 5))\n",
    "    \n",
    "    def draw_grid(ax, grid, title):\n",
    "        ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "        ax.set_xlim(0, 9)\n",
    "        ax.set_ylim(0, 9)\n",
    "        ax.set_xticks(range(10))\n",
    "        ax.set_yticks(range(10))\n",
    "        ax.grid(True, linewidth=0.5)\n",
    "        \n",
    "        for i in range(0, 10, 3):\n",
    "            ax.axhline(i, color='black', linewidth=2)\n",
    "            ax.axvline(i, color='black', linewidth=2)\n",
    "        \n",
    "        grid_2d = grid.reshape(9, 9)\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if grid_2d[i, j] != 0:\n",
    "                    ax.text(j + 0.5, 8.5 - i, str(grid_2d[i, j]),\n",
    "                           ha='center', va='center', fontsize=12)\n",
    "        \n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    draw_grid(axes[0], quiz, \"Puzzle\")\n",
    "    draw_grid(axes[1], solution, \"Solution\")\n",
    "    if prediction is not None:\n",
    "        draw_grid(axes[2], prediction, \"Prediction\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "model_path = os.path.join(config.save_dir, config.model_name)\n",
    "if os.path.exists(model_path):\n",
    "    trained_model = load_model(model_path, config)\n",
    "    \n",
    "    print(\"\\nTesting on validation examples:\")\n",
    "    for i in range(3):\n",
    "        idx = np.random.randint(0, len(val_dataset))\n",
    "        quiz_onehot, solution_target = val_dataset[idx]\n",
    "        \n",
    "        quiz = dataset.quizzes[val_dataset.indices[idx]]\n",
    "        solution = dataset.solutions[val_dataset.indices[idx]]\n",
    "        \n",
    "        prediction = predict_sudoku(trained_model, quiz, config)\n",
    "        \n",
    "        accuracy = (prediction == solution).mean() * 100\n",
    "        print(f\"\\nExample {i+1} - Accuracy: {accuracy:.2f}%\")\n",
    "        \n",
    "        visualize_sudoku(quiz, solution, prediction)\n",
    "else:\n",
    "    print(f\"Model not found at {model_path}. Please train the model first.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_production_model(model, config: TRMConfig, filename: str = \"trm_sudoku_production.pt\"):\n",
    "    save_path = os.path.join(config.save_dir, filename)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'config': config\n",
    "    }, save_path)\n",
    "    print(f\"\\nProduction model saved to: {save_path}\")\n",
    "    print(f\"Model size: {os.path.getsize(save_path) / 1024 / 1024:.2f} MB\")\n",
    "    return save_path\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    production_path = save_production_model(trained_model, config)\n",
    "    print(\"\\nModel ready for deployment!\")\n",
    "    print(f\"  Load with: torch.load('{production_path}')\")\n",
    "else:\n",
    "    print(\"Train the model first before saving for production.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
